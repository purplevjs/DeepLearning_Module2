# Deep Learning Module 2: Sentence Analysis Models

This project provides a suite of models for analyzing sentences, extracting importance ratings, and determining long-term storage classifications.

## Setup and Running the Project
Requirements
*Python 3.7+
*PyTorch
*Transformers (Hugging Face)
*scikit-learn
*pandas
*matplotlib
*seaborn

Install the required packages:
pip install torch transformers pandas scikit-learn matplotlib seaborn

## Data Source
Generated by Chagpt, Claude and Deepseek.

## Previous Research
No previous research yet.

## Data Structure
The project expects CSV files in the ./Data directory with columns for sentences, importance ratings, and long-term storage classification.

## Running the Project
The simplest way to run the project is using the main script:
python main.py

This will present a menu with options to:
Train the RoBERTa model (standard training)
Train the RoBERTa model (with cross-validation)
Train the SVM model
Train the naive word-matching approach
Train all models

## Running Individual Model Training Scripts
To run individual training scripts directly:
RoBERTa Model (Standard Training):
python scripts/Final_Train.py

RoBERTa Model (Cross-Validation):
python scripts/Train.py

SVM Model:
python scripts/machine_learning_svm.py

Naive Approach:
python scripts/naive_approach.py

## Project Structure and File Descriptions

### Core Scripts
main.py: Main entry point with a user-friendly interface to select training methods.
setup.py: Contains functions for initializing and running different model training processes.

### Data Processing
scripts/Data_preprocess.py: Handles data preprocessing, loading CSV files from the Data folder, and preparing them for model training. It standardizes column names and normalizes binary classification values.
scripts/Dataset_Class.py: Defines the custom TextDataset class that handles text data for PyTorch models. It converts text inputs into tokenized tensors that can be consumed by the deep learning models.

### Models
scripts/Model_Class.py: Implements the DistinguishModel class using RoBERTa as the backbone. It features:
Separate heads for regression (importance) and classification (long-term storage)
Residual connections for improved feature extraction
Selective layer freezing for efficient fine-tuning

### Training Scripts
scripts/Final_Train.py: Implements standard training for the RoBERTa model with early stopping, learning rate scheduling, and best model saving.
scripts/Train.py: Implements k-fold cross-validation training for the RoBERTa model, which provides more robust performance evaluation across different data splits.
scripts/machine_learning_svm.py: Trains Support Vector Machine models for both classification and regression tasks using TF-IDF text representation. It generates comprehensive evaluation metrics and visualizations.
scripts/naive_approach.py: Implements a simple word-matching approach for baseline comparison, identifying relevant keywords to predict long-term storage.

### Training Outputs
Each training script generates:
Model files: Saved models that can be loaded for inference
Performance metrics: Accuracy, precision, recall, F1-score for classification; MSE/RÂ² for regression
Visualizations: Loss curves, confusion matrices, ROC curves, etc.
Prediction results: CSV files with true and predicted values

### Project Workflow
1. Data is preprocessed and normalized
2. Models are initialized with appropriate architectures
3. Training is performed with task-specific loss functions
4. Performance is evaluated with appropriate metrics
5. Results are saved for comparison and future use
This project demonstrates multiple approaches to sentence analysis, from simple rule-based methods to complex deep learning architectures, enabling comparison of different techniques for the same tasks.